{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "from sklearn import datasets\n",
    "\n",
    "# model training and evalutation utilities \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold # this is one way to generate folds\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# toy data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you should learn/be aware of based on this lecture \n",
    "\n",
    "Key `sklearn` functions:\n",
    "- `train_test_split`\n",
    "- `cross_validate`\n",
    "- Fold generators: `KFold` and `StratifiedKFold`\n",
    "- Scoring functions per last lecture and how to pass to `cross_validate`\n",
    "- How to compare different models by looping over them with `cross_validate`, `GridSearchCV`, or `RandomizedSearchCV` \n",
    "\n",
    "Not covered today but you should check out:\n",
    "- `confusion_matrix` and `classification_report` (helpful to evaluate models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple \"split, train, evaluate\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "# ignore the model I choose here, its not important what\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X1, y1) # fit on the \"training data\" X1 and  y1\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2) # using X2 (out-of-sample data), predict y2\n",
    "accuracy_score(y2, y2_model) # see how close y2 is to prediction (fraction of all pred that are exactly right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to do k-fold? It's like repeating the above. In pseudo code, it looks like:\n",
    "1. Break the X and y data into $k$ subsamples\n",
    "2. For each subsample, fit the model, predict OOS, score predictions, and save those\n",
    "\n",
    "Ok?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold in Python: The explicit way, and the wrapped way\n",
    "\n",
    "Watch me do the explicit way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can take quick notes here, but I'm not going to write this code slow enough to copy\n",
    "# the point here is to illustrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the wrapper below! We are going to see how to use that function to:\n",
    "- try multiple models\n",
    "- try different sets of X variables\n",
    "- try different ways to specific folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try here with diff scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the metrics it can compute out of the box are here: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Notice that many of these were discussed in our last lecture!\n",
    "\n",
    "_**Warning/Note:**_ the metric names on that link and what you put in the `scoring` dictionary don't seem to match up.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the `cross_validate` parameters\n",
    "\n",
    "### The model parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linear_model` submodule contains lots of useful alternate options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example:\n",
    "linear_model.Lasso\n",
    "linear_model.Ridge\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "linear_model.LassoCV() # Returns a Lasso (L1 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.RidgeCV() # Returns a Ridge (L2 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.LogisticRegressionCV() # return best logit model by CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up models to try\n",
    "models = []\n",
    "models.append(('svc_1', SVC(gamma='auto') ))\n",
    "models.append(('svc_2', SVC(C=5) ))\n",
    "models.append(('neighbor',  KNeighborsClassifier(n_neighbors=1)))\n",
    "\n",
    "# loop and print\n",
    "for name, model in models:\n",
    "    scores = cross_validate(model, X, y, scoring='accuracy')\n",
    "    print('%s: %.3f (%.3f)' % (name.ljust(10), \n",
    "                                   scores['test_score'].mean(), \n",
    "                                   scores['test_score'].std()\n",
    "                                   )\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The X parameter\n",
    "\n",
    "You can loop over Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a smaller X and a bigger X\n",
    "X_small = X[:,:2] # just first two columns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X3 = poly.fit_transform(X)\n",
    "\n",
    "# set up Xs to try\n",
    "right here!\n",
    "\n",
    "# loop and print\n",
    "right here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xs and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV parameter and folds\n",
    "\n",
    "Just  watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links, resoruces, and next week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only two resources needed\n",
    "- sklearn docs are GREAT https://scikit-learn.org/stable/user_guide.html \n",
    "- Python Data Science Handbook (note some module calls are obsolete, so you might need to update code) https://jakevdp.github.io/PythonDataScienceHandbook/index.html\n",
    "\n",
    "Next week:\n",
    "- preprocessing\n",
    "- data transformations\n",
    "- feasture selection\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
